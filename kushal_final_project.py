# -*- coding: utf-8 -*-
"""kushal_final_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tX5tlOT5_2sYHCanUk_g-sa4a_5xUJj6
"""

import pandas as pd
import random

# List of Nike items
nike_items = [
    "Running Shoes",      # Popular for running and casual wear
    "Soccer Shoes",       # Used for playing soccer/football
    "Socks",              # Sports socks, ankle socks, etc.
    "Swimming Shirt",     # For swimming and water sports
    "Dry Fit V-Neck",     # A moisture-wicking athletic shirt
    "Rash Guard",         # Protective wear for water sports or workouts
    "Sweatshirts",        # For warmth and casual wear
    "Hoodies",            # Casual or sports hoodies for colder weather
    "Tech Pants",         # Performance pants for sports or training
    "Modern Pants"        # Fashionable casual or sports pants
]

# List of Amazon items
amazon_items = [
    "Echo Dot",           # Smart speaker
    "Kindle Paperwhite",   # E-reader
    "Fire TV Stick",       # Streaming device
    "Wireless Mouse",      # Computer accessory
    "Bluetooth Speaker",   # Portable speaker
    "Phone Charger",       # USB charger
    "Fitness Tracker",     # Wearable fitness device
    "Laptop Sleeve",       # Protective case for laptops
    "Smart Light Bulbs",   # Home automation lighting
    "Noise Cancelling Headphones"  # Audio accessory
]

# List of Walmart items
walmart_items = [
    "BBQ Grill",          # Outdoor grill
    "Vacuum Cleaner",     # Home cleaning device
    "Microwave Oven",     # Kitchen appliance
    "Blender",            # Kitchen appliance
    "Towel Set",          # Bathroom accessory
    "Camping Tent",       # Outdoor tent for camping
    "Yoga Mat",           # Fitness accessory
    "Office Chair",       # Furniture
    "Electric Kettle",    # Kitchen appliance
    "Air Fryer"           # Kitchen appliance
]

# Create 20 transactions for each store (Nike, Amazon, and Walmart)
all_transactions = []
stores = {
    "Nike": nike_items,
    "Amazon": amazon_items,
    "Walmart": walmart_items
}

for store, items in stores.items():
    for i in range(1, 21):
        num_items = random.randint(2, 6)  # Each transaction will have 2 to 6 items
        transaction_items = random.sample(items, num_items)
        all_transactions.append({
            "Transaction ID": f"{store}Trans{i}",
            "Store": store,
            "Items": ", ".join(transaction_items)
        })

# Convert to DataFrame
df_transactions = pd.DataFrame(all_transactions)

# Save to CSV
df_transactions.to_csv("store_transactions.csv", index=False)

print("Transactions saved to 'store_transactions.csv'.")

import pandas as pd
import random

# Define the Nike items
nike_items = [
    "Running Shoes",
    "Soccer Shoes",
    "Socks",
    "Swimming Shirt",
    "Dry Fit V-Neck",
    "Rash Guard",
    "Sweatshirts",
    "Hoodies",
    "Tech Pants",
    "Modern Pants"
]

# Define the Amazon items
amazon_items = [
    "Echo Dot",
    "Kindle Paperwhite",
    "Fire TV Stick",
    "Wireless Mouse",
    "Bluetooth Speaker",
    "Phone Charger",
    "Fitness Tracker",
    "Laptop Sleeve",
    "Smart Light Bulbs",
    "Noise Cancelling Headphones"
]

# Define the Walmart items
walmart_items = [
    "BBQ Grill",
    "Vacuum Cleaner",
    "Microwave Oven",
    "Blender",
    "Towel Set",
    "Camping Tent",
    "Yoga Mat",
    "Office Chair",
    "Electric Kettle",
    "Air Fryer"
]

# Define transactions for each database (Nike, Amazon, Walmart)
transactions_db_nike = [
    ["Running Shoes", "Socks", "Sweatshirts"],
    ["Soccer Shoes", "Socks"],
    ["Swimming Shirt", "Dry Fit V-Neck"],
    ["Rash Guard", "Hoodies", "Tech Pants"],
    ["Modern Pants", "Sweatshirts"],
    # Add more as needed
]

transactions_db_amazon = [
    ["Echo Dot", "Fire TV Stick"],
    ["Kindle Paperwhite", "Phone Charger", "Wireless Mouse"],
    ["Fitness Tracker", "Smart Light Bulbs"],
    ["Bluetooth Speaker", "Noise Cancelling Headphones"],
    ["Laptop Sleeve", "Echo Dot", "Phone Charger"],
    # Add more as needed
]

transactions_db_walmart = [
    ["BBQ Grill", "Camping Tent"],
    ["Vacuum Cleaner", "Air Fryer"],
    ["Blender", "Yoga Mat", "Towel Set"],
    ["Microwave Oven", "Electric Kettle"],
    ["Office Chair", "Blender"],
    # Add more as needed
]

# Function to save transactions to CSV
def save_transactions(transactions, db_number, store_name):
    df_transactions = pd.DataFrame({
        "Transaction ID": [f"{store_name}Trans{j+1} DB{db_number}" for j in range(len(transactions))],
        "Items": [", ".join(transaction) for transaction in transactions]
    })
    df_transactions.to_csv(f"{store_name.lower()}_transactions_db{db_number}.csv", index=False)

# Save each Nike, Amazon, and Walmart database
save_transactions(transactions_db_nike, 1, "Nike")
save_transactions(transactions_db_amazon, 1, "Amazon")
save_transactions(transactions_db_walmart, 1, "Walmart")

print("Nike, Amazon, and Walmart databases saved successfully!")

import pandas as pd
from itertools import combinations
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.frequent_patterns import fpgrowth
import time

# Define Nike, Amazon, and Walmart items for all transactions
nike_items = [
    "Running Shoes", "Soccer Shoes", "Socks", "Swimming Shirt", "Dry Fit V-Neck",
    "Rash Guard", "Sweatshirts", "Hoodies", "Tech Pants", "Modern Pants"
]

amazon_items = [
    "Echo Dot", "Kindle Paperwhite", "Fire TV Stick", "Wireless Mouse", "Bluetooth Speaker",
    "Phone Charger", "Fitness Tracker", "Laptop Sleeve", "Smart Light Bulbs", "Noise Cancelling Headphones"
]

walmart_items = [
    "BBQ Grill", "Vacuum Cleaner", "Microwave Oven", "Blender", "Towel Set",
    "Camping Tent", "Yoga Mat", "Office Chair", "Electric Kettle", "Air Fryer"
]

# Transactions for Nike, Amazon, and Walmart
transactions_db = {
    'Nike': [
        ["Running Shoes", "Socks", "Sweatshirts"], ["Soccer Shoes", "Socks"], ["Swimming Shirt", "Dry Fit V-Neck"],
        ["Rash Guard", "Hoodies", "Tech Pants"], ["Modern Pants", "Sweatshirts"]
    ],
    'Amazon': [
        ["Echo Dot", "Fire TV Stick"], ["Kindle Paperwhite", "Phone Charger", "Wireless Mouse"],
        ["Fitness Tracker", "Smart Light Bulbs"], ["Bluetooth Speaker", "Noise Cancelling Headphones"],
        ["Laptop Sleeve", "Echo Dot", "Phone Charger"]
    ],
    'Walmart': [
        ["BBQ Grill", "Camping Tent"], ["Vacuum Cleaner", "Air Fryer"], ["Blender", "Yoga Mat", "Towel Set"],
        ["Microwave Oven", "Electric Kettle"], ["Office Chair", "Blender"]
    ]
}

# Prompt user for input
min_support = float(input("Enter minimum support (e.g., 0.2): "))
min_confidence = float(input("Enter minimum confidence (e.g., 0.7): "))

# Convert transactions to DataFrame with binary encoding for apriori and fp-growth
def encode_transactions(transactions, items):
    encoded_vals = []
    for transaction in transactions:
        encoded_transaction = {item: (item in transaction) for item in items}
        encoded_vals.append(encoded_transaction)
    return pd.DataFrame(encoded_vals)

# Brute Force Implementation
def brute_force(transactions, items, min_support):
    start_time = time.time()

    def calculate_support(itemset, transactions):
        count = 0
        for transaction in transactions:
            if itemset.issubset(transaction):
                count += 1
        return count / len(transactions)

    def find_frequent_itemsets(items, transactions, size, min_support):
        itemsets = [set(combo) for combo in combinations(items, size)]
        frequent_itemsets = []
        for itemset in itemsets:
            support = calculate_support(itemset, transactions)
            if support >= min_support:
                frequent_itemsets.append((itemset, support))
        return frequent_itemsets

    k = 1
    frequent_itemsets = []
    while True:
        current_frequent_itemsets = find_frequent_itemsets(items, transactions, k, min_support)
        if len(current_frequent_itemsets) == 0:
            break
        frequent_itemsets.extend(current_frequent_itemsets)
        k += 1

    # Generate association rules
    rules = []
    for itemset, support in frequent_itemsets:
        if len(itemset) > 1:
            for consequent in itemset:
                antecedent = itemset - {consequent}
                if len(antecedent) > 0:
                    confidence = calculate_support(itemset, transactions) / calculate_support(antecedent, transactions)
                    if confidence >= min_confidence:
                        rules.append((antecedent, consequent, confidence))

    brute_force_time = time.time() - start_time
    return frequent_itemsets, rules, brute_force_time

# Apriori Implementation
def apriori_algorithm(df, min_support, min_confidence):
    start_time = time.time()
    frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True)
    rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=min_confidence)
    apriori_time = time.time() - start_time
    return frequent_itemsets, rules, apriori_time

# FP-Growth Implementation
def fpgrowth_algorithm(df, min_support, min_confidence):
    start_time = time.time()
    frequent_itemsets = fpgrowth(df, min_support=min_support, use_colnames=True)
    rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=min_confidence)
    fpgrowth_time = time.time() - start_time
    return frequent_itemsets, rules, fpgrowth_time

# Main comparison function
def compare_algorithms(transactions_db, items, min_support, min_confidence):
    for store, transactions in transactions_db.items():
        print(f"\n--- Store: {store} ---")
        transactions = [set(t) for t in transactions]
        item_list = nike_items if store == 'Nike' else amazon_items if store == 'Amazon' else walmart_items

        # Brute Force
        frequent_itemsets_bf, rules_bf, bf_time = brute_force(transactions, item_list, min_support)
        print(f"Brute Force Time: {bf_time:.4f} seconds")
        print(f"Frequent Itemsets (Brute Force): {frequent_itemsets_bf}")
        print(f"Association Rules (Brute Force): {rules_bf}")

        # Apriori
        df_encoded = encode_transactions(transactions, item_list)
        frequent_itemsets_ap, rules_ap, ap_time = apriori_algorithm(df_encoded, min_support, min_confidence)
        print(f"Apriori Time: {ap_time:.4f} seconds")
        print(f"Frequent Itemsets (Apriori):\n{frequent_itemsets_ap}")
        print(f"Association Rules (Apriori):\n{rules_ap}")

        # FP-Growth
        frequent_itemsets_fp, rules_fp, fp_time = fpgrowth_algorithm(df_encoded, min_support, min_confidence)
        print(f"FP-Growth Time: {fp_time:.4f} seconds")
        print(f"Frequent Itemsets (FP-Growth):\n{frequent_itemsets_fp}")
        print(f"Association Rules (FP-Growth):\n{rules_fp}")

# Run the comparison for all stores and their databases
compare_algorithms(transactions_db, nike_items, min_support, min_confidence)



pip install pyarrow==14.0.1

from itertools import combinations

# Define items for Nike, Amazon, and Walmart
nike_items = [
    "Running Shoes", "Soccer Shoes", "Socks", "Swimming Shirt", "Dry Fit V-Neck",
    "Rash Guard", "Sweatshirts", "Hoodies", "Tech Pants", "Modern Pants"
]

amazon_items = [
    "Laptop", "Headphones", "Mouse", "Keyboard", "Monitor",
    "Smartphone", "Tablet", "Charger", "USB Cable", "HDMI Cable"
]

walmart_items = [
    "Milk", "Bread", "Eggs", "Butter", "Cheese",
    "Cereal", "Chicken", "Beef", "Pasta", "Rice"
]

# Transactions for Nike
nike_transactions = [
    ["Running Shoes", "Socks", "Sweatshirts"],
    ["Soccer Shoes", "Socks"],
    ["Swimming Shirt", "Dry Fit V-Neck"],
    ["Rash Guard", "Hoodies", "Tech Pants"],
    ["Modern Pants", "Sweatshirts"],
    ["Running Shoes", "Swimming Shirt"],
    ["Dry Fit V-Neck", "Soccer Shoes"],
    ["Socks", "Sweatshirts", "Tech Pants"],
    ["Hoodies", "Rash Guard", "Modern Pants"],
    ["Socks", "Swimming Shirt"],
    ["Tech Pants", "Sweatshirts"],
    ["Running Shoes", "Soccer Shoes", "Hoodies"]
]

# Transactions for Amazon
amazon_transactions = [
    ["Laptop", "Headphones", "Mouse"],
    ["Smartphone", "Charger"],
    ["Tablet", "Keyboard"],
    ["Monitor", "HDMI Cable", "USB Cable"],
    ["Laptop", "Charger", "USB Cable"],
    ["Smartphone", "Headphones"],
    ["Mouse", "Keyboard"],
    ["Tablet", "USB Cable"],
    ["Monitor", "Laptop"],
    ["Smartphone", "HDMI Cable"],
    ["Charger", "USB Cable"],
    ["Laptop", "Smartphone", "Charger"],
]

# Transactions for Walmart
walmart_transactions = [
    ["Milk", "Bread", "Eggs"],
    ["Chicken", "Rice"],
    ["Pasta", "Butter"],
    ["Beef", "Cheese", "Eggs"],
    ["Milk", "Cereal", "Bread"],
    ["Chicken", "Pasta"],
    ["Beef", "Rice"],
    ["Butter", "Eggs"],
    ["Cereal", "Milk", "Bread"],
    ["Pasta", "Butter"],
    ["Chicken", "Rice"],
    ["Cheese", "Eggs"],
]

# Minimum support and confidence
min_support = 2
min_confidence = 0.7

def calculate_support(itemset, transactions):
    count = 0
    for transaction in transactions:
        if itemset.issubset(transaction):
            count += 1
    return count

def find_frequent_itemsets(items, transactions, size, min_support):
    itemsets = [set(combo) for combo in combinations(items, size)]
    frequent_itemsets = []
    for itemset in itemsets:
        support = calculate_support(itemset, transactions)
        if support >= min_support:
            frequent_itemsets.append((itemset, support))
    return frequent_itemsets

def brute_force_frequent_itemsets(items, transactions, min_support):
    k = 1
    frequent_itemsets = []
    while True:
        current_frequent_itemsets = find_frequent_itemsets(items, transactions, k, min_support)
        if len(current_frequent_itemsets) == 0:
            break
        frequent_itemsets.extend(current_frequent_itemsets)
        k += 1
    return frequent_itemsets

def generate_association_rules(frequent_itemsets, transactions, min_support, min_confidence):
    rules = []
    transaction_count = len(transactions)

    def calculate_support(itemset):
        count = sum(1 for transaction in transactions if itemset.issubset(transaction))
        return count / transaction_count

    for itemset, support in frequent_itemsets:
        if len(itemset) < 2:
            continue

        for i in range(1, len(itemset)):
            for antecedent in combinations(itemset, i):
                antecedent = set(antecedent)
                consequent = itemset - antecedent

                antecedent_support = calculate_support(antecedent)
                confidence = support / antecedent_support if antecedent_support > 0 else 0

                if confidence >= min_confidence:
                    rules.append([antecedent, consequent, support, confidence])

    return rules

# Function to process Nike, Amazon, and Walmart
def process_transactions(transactions, items, store_name):
    print(f"\n--- {store_name} ---")
    frequent_itemsets = brute_force_frequent_itemsets(items, [set(t) for t in transactions], min_support)
    association_rules = generate_association_rules(frequent_itemsets, [set(t) for t in transactions], min_support, min_confidence)

    print("Frequent Itemsets:")
    for itemset, support in frequent_itemsets:
        print(f"Itemset: {itemset}, Support: {support}")

    print("\nAssociation Rules:")
    for antecedent, consequent, support, confidence in association_rules:
        print(f"Rule: {antecedent} -> {consequent}, Support={support}, Confidence={confidence}")

# Process transactions for each store
process_transactions(nike_transactions, nike_items, "Nike")
process_transactions(amazon_transactions, amazon_items, "Amazon")
process_transactions(walmart_transactions, walmart_items, "Walmart")

from itertools import combinations

# Define items for Nike, Amazon, and Walmart
nike_items = [
    "Running Shoes", "Soccer Shoes", "Socks", "Swimming Shirt", "Dry Fit V-Neck",
    "Rash Guard", "Sweatshirts", "Hoodies", "Tech Pants", "Modern Pants"
]

amazon_items = [
    "Laptop", "Headphones", "Mouse", "Keyboard", "Monitor",
    "Smartphone", "Tablet", "Charger", "USB Cable", "HDMI Cable"
]

walmart_items = [
    "Milk", "Bread", "Eggs", "Butter", "Cheese",
    "Cereal", "Chicken", "Beef", "Pasta", "Rice"
]

# Transactions for Nike
nike_transactions = [
    ["Running Shoes", "Socks", "Sweatshirts"],
    ["Soccer Shoes", "Socks"],
    ["Swimming Shirt", "Dry Fit V-Neck"],
    ["Rash Guard", "Hoodies", "Tech Pants"],
    ["Modern Pants", "Sweatshirts"],
    ["Running Shoes", "Swimming Shirt"],
    ["Dry Fit V-Neck", "Soccer Shoes"],
    ["Socks", "Sweatshirts", "Tech Pants"],
    ["Hoodies", "Rash Guard", "Modern Pants"],
    ["Socks", "Swimming Shirt"],
    ["Tech Pants", "Sweatshirts"],
    ["Running Shoes", "Soccer Shoes", "Hoodies"]
]

# Transactions for Amazon
amazon_transactions = [
    ["Laptop", "Headphones", "Mouse"],
    ["Smartphone", "Charger"],
    ["Tablet", "Keyboard"],
    ["Monitor", "HDMI Cable", "USB Cable"],
    ["Laptop", "Charger", "USB Cable"],
    ["Smartphone", "Headphones"],
    ["Mouse", "Keyboard"],
    ["Tablet", "USB Cable"],
    ["Monitor", "Laptop"],
    ["Smartphone", "HDMI Cable"],
    ["Charger", "USB Cable"],
    ["Laptop", "Smartphone", "Charger"],
]

# Transactions for Walmart
walmart_transactions = [
    ["Milk", "Bread", "Eggs"],
    ["Chicken", "Rice"],
    ["Pasta", "Butter"],
    ["Beef", "Cheese", "Eggs"],
    ["Milk", "Cereal", "Bread"],
    ["Chicken", "Pasta"],
    ["Beef", "Rice"],
    ["Butter", "Eggs"],
    ["Cereal", "Milk", "Bread"],
    ["Pasta", "Butter"],
    ["Chicken", "Rice"],
    ["Cheese", "Eggs"],
]

# Minimum support and confidence
min_support = 2
min_confidence = 0.7

def calculate_support(itemset, transactions):
    count = 0
    for transaction in transactions:
        if itemset.issubset(transaction):
            count += 1
    return count

def find_frequent_itemsets(items, transactions, size, min_support):
    itemsets = [set(combo) for combo in combinations(items, size)]
    frequent_itemsets = []
    for itemset in itemsets:
        support = calculate_support(itemset, transactions)
        if support >= min_support:
            frequent_itemsets.append((itemset, support))
    return frequent_itemsets

def brute_force_frequent_itemsets(items, transactions, min_support):
    k = 1
    frequent_itemsets = []
    while True:
        current_frequent_itemsets = find_frequent_itemsets(items, transactions, k, min_support)
        if len(current_frequent_itemsets) == 0:
            break
        frequent_itemsets.extend(current_frequent_itemsets)
        k += 1
    return frequent_itemsets

def generate_association_rules(frequent_itemsets, transactions, min_support, min_confidence):
    rules = []
    transaction_count = len(transactions)

    def calculate_support(itemset):
        count = sum(1 for transaction in transactions if itemset.issubset(transaction))
        return count / transaction_count

    for itemset, support in frequent_itemsets:
        if len(itemset) < 2:
            continue

        for i in range(1, len(itemset)):
            for antecedent in combinations(itemset, i):
                antecedent = set(antecedent)
                consequent = itemset - antecedent

                antecedent_support = calculate_support(antecedent)
                confidence = support / antecedent_support if antecedent_support > 0 else 0

                if confidence >= min_confidence:
                    rules.append([antecedent, consequent, support, confidence])

    return rules

# Function to process Nike, Amazon, and Walmart
def process_transactions(transactions, items, store_name):
    print(f"\n--- {store_name} ---")
    frequent_itemsets = brute_force_frequent_itemsets(items, [set(t) for t in transactions], min_support)
    association_rules = generate_association_rules(frequent_itemsets, [set(t) for t in transactions], min_support, min_confidence)

    print("Frequent Itemsets:")
    for itemset, support in frequent_itemsets:
        print(f"Itemset: {itemset}, Support: {support}")

    print("\nAssociation Rules:")
    for antecedent, consequent, support, confidence in association_rules:
        print(f"Rule: {antecedent} -> {consequent}, Support={support}, Confidence={confidence}")

# Process transactions for each store
process_transactions(nike_transactions, nike_items, "Nike")
process_transactions(amazon_transactions, amazon_items, "Amazon")
process_transactions(walmart_transactions, walmart_items, "Walmart")

!pip install mlxtend
import pandas as pd
from itertools import combinations
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.frequent_patterns import fpgrowth
import time

# Define items for Nike, Amazon, and Walmart
nike_items = [
    "Running Shoes", "Soccer Shoes", "Socks", "Swimming Shirt", "Dry Fit V-Neck",
    "Rash Guard", "Sweatshirts", "Hoodies", "Tech Pants", "Modern Pants"
]

amazon_items = [
    "Laptop", "Headphones", "Mouse", "Keyboard", "Monitor",
    "Smartphone", "Tablet", "Charger", "USB Cable", "HDMI Cable"
]

walmart_items = [
    "Milk", "Bread", "Eggs", "Butter", "Cheese",
    "Cereal", "Chicken", "Beef", "Pasta", "Rice"
]

# Transactions for Nike, Amazon, and Walmart
transactions_db = {
    "Nike": [
        ["Running Shoes", "Socks", "Sweatshirts"], ["Soccer Shoes", "Socks"], ["Swimming Shirt", "Dry Fit V-Neck"],
        ["Rash Guard", "Hoodies", "Tech Pants"], ["Modern Pants", "Sweatshirts"]
    ],
    "Amazon": [
        ["Laptop", "Headphones", "Mouse"], ["Smartphone", "Charger"], ["Tablet", "Keyboard"],
        ["Monitor", "HDMI Cable", "USB Cable"], ["Laptop", "Charger", "USB Cable"]
    ],
    "Walmart": [
        ["Milk", "Bread", "Eggs"], ["Chicken", "Rice"], ["Pasta", "Butter"],
        ["Beef", "Cheese", "Eggs"], ["Milk", "Cereal", "Bread"]
    ]
}

# Prompt user for input
min_support = float(input("Enter minimum support (e.g., 0.2): "))
min_confidence = float(input("Enter minimum confidence (e.g., 0.7): "))

# Convert transactions to DataFrame with binary encoding for apriori and fp-growth
def encode_transactions(transactions, items):
    encoded_vals = []
    for transaction in transactions:
        encoded_transaction = {item: (item in transaction) for item in items}
        encoded_vals.append(encoded_transaction)
    return pd.DataFrame(encoded_vals)

# Brute Force Implementation
def brute_force(transactions, items, min_support):
    start_time = time.time()

    def calculate_support(itemset, transactions):
        count = 0
        for transaction in transactions:
            if itemset.issubset(transaction):
                count += 1
        return count / len(transactions)

    def find_frequent_itemsets(items, transactions, size, min_support):
        itemsets = [set(combo) for combo in combinations(items, size)]
        frequent_itemsets = []
        for itemset in itemsets:
            support = calculate_support(itemset, transactions)
            if support >= min_support:
                frequent_itemsets.append((itemset, support))
        return frequent_itemsets

    k = 1
    frequent_itemsets = []
    while True:
        current_frequent_itemsets = find_frequent_itemsets(items, transactions, k, min_support)
        if len(current_frequent_itemsets) == 0:
            break
        frequent_itemsets.extend(current_frequent_itemsets)
        k += 1

    # Generate association rules
    rules = []
    for itemset, support in frequent_itemsets:
        if len(itemset) > 1:
            for consequent in itemset:
                antecedent = itemset - {consequent}
                if len(antecedent) > 0:
                    confidence = calculate_support(itemset, transactions) / calculate_support(antecedent, transactions)
                    if confidence >= min_confidence:
                        rules.append((list(antecedent), list(consequent), confidence, support))

    brute_force_time = time.time() - start_time
    return frequent_itemsets, rules, brute_force_time

# Apriori Implementation
def apriori_algorithm(df, min_support, min_confidence):
    start_time = time.time()
    frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True)
    rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=min_confidence)
    rules['antecedents'] = rules['antecedents'].apply(lambda x: list(x))
    rules['consequents'] = rules['consequents'].apply(lambda x: list(x))
    apriori_time = time.time() - start_time
    return frequent_itemsets, rules, apriori_time

# FP-Growth Implementation
def fpgrowth_algorithm(df, min_support, min_confidence):
    start_time = time.time()
    frequent_itemsets = fpgrowth(df, min_support=min_support, use_colnames=True)
    rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=min_confidence)
    rules['antecedents'] = rules['antecedents'].apply(lambda x: list(x))
    rules['consequents'] = rules['consequents'].apply(lambda x: list(x))
    fpgrowth_time = time.time() - start_time
    return frequent_itemsets, rules, fpgrowth_time

# Main comparison function
def compare_algorithms(transactions_db, items_db, min_support, min_confidence):
    for store, transactions in transactions_db.items():
        print(f"\n--- {store} ---")
        items = items_db[store]
        transactions = [set(t) for t in transactions]

        # Brute Force
        frequent_itemsets_bf, rules_bf, bf_time = brute_force(transactions, items, min_support)
        print(f"Brute Force Time: {bf_time:.4f} seconds")
        print(f"Frequent Itemsets (Brute Force): {frequent_itemsets_bf}")

        if rules_bf:
            print("\nFinal Association Rules (Brute Force):")
            for idx, (antecedent, consequent, confidence, support) in enumerate(rules_bf, start=1):
                print(f"Rule {idx}: {antecedent} -> {consequent}")
                print(f"Confidence: {confidence * 100:.2f}%")
                print(f"Support: {support * 100:.2f}%\n")

        # Apriori
        df_encoded = encode_transactions(transactions, items)
        frequent_itemsets_ap, rules_ap, ap_time = apriori_algorithm(df_encoded, min_support, min_confidence)
        print(f"Apriori Time: {ap_time:.4f} seconds")
        print(f"Frequent Itemsets (Apriori):\n{frequent_itemsets_ap}")

        if not rules_ap.empty:
            print("\nFinal Association Rules (Apriori):")
            for idx, row in rules_ap.iterrows():
                print(f"Rule {idx + 1}: {row['antecedents']} -> {row['consequents']}")
                print(f"Confidence: {row['confidence'] * 100:.2f}%")
                print(f"Support: {row['support'] * 100:.2f}%\n")

        # FP-Growth
        frequent_itemsets_fp, rules_fp, fp_time = fpgrowth_algorithm(df_encoded, min_support, min_confidence)
        print(f"FP-Growth Time: {fp_time:.4f} seconds")
        print(f"Frequent Itemsets (FP-Growth):\n{frequent_itemsets_fp}")

        if not rules_fp.empty:
            print("\nFinal Association Rules (FP-Growth):")
            for idx, row in rules_fp.iterrows():
                print(f"Rule {idx + 1}: {row['antecedents']} -> {row['consequents']}")
                print(f"Confidence: {row['confidence'] * 100:.2f}%")
                print(f"Support: {row['support'] * 100:.2f}%\n")

# Dictionary of item sets for each store
items_db = {
    "Nike": nike_items,
    "Amazon": amazon_items,
    "Walmart": walmart_items
}

# Run the comparison for Nike, Amazon, and Walmart
compare_algorithms(transactions_db, items_db, min_support, min_confidence)

"""# New Section

# New Section
"""